{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Decision Tree?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div  style=\"color:blue;font-family:Candara,arial,helvetica;line-height:20px\"><strong>\n",
    "\n",
    "## Decision Trees are a type of Supervised Machine Learning (that is you explain what the input is and what the corresponding output is in the training data) where the data is continuously split according to a certain parameter. The tree can be explained by two entities, namely decision nodes and leaves. The leaves are the decisions or the final outcomes. And the decision nodes are where the data is split.\n",
    "    \n",
    "<img src=\"https://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1545934190/1_r5ikdb.png\" alt=\"drawing\" width=\"600\" height=\"300\"/>     \n",
    "    \n",
    "<img src=\"https://www.xoriant.com/blog/wp-content/uploads/2017/08/Decision-Trees-modified-1.png \" alt=\"drawing\" width=\"600\" height=\"300\"/>     \n",
    "   \n",
    "    \n",
    "</strong></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"1000\"\n",
       "            src=\"https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x25c89c5b608>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(src='https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html', width=1000, height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impurity Criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTUu8H6L79w3fZK0CLt9FMgqOQp1jBQmWLYp18tOPZmtPEj37sgpg&s \" alt=\"drawing\" width=\"600\" height=\"300\"/> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run and Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Import Libraries and split data to test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Read dataset\n",
    "data = pd.read_csv('04 - decisiontreeAdultIncome.csv')\n",
    "\n",
    "# Check for Null values\n",
    "data.isnull().sum(axis=0)\n",
    "\n",
    "# Create Dummy variables\n",
    "data.dtypes\n",
    "data_prep = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "\n",
    "# Create X and Y Variables\n",
    "X = data_prep.iloc[:, :-1]\n",
    "Y = data_prep.iloc[:, -1]\n",
    "\n",
    "\n",
    "# Split the X and Y dataset into training and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = \\\n",
    "train_test_split(X, Y, test_size = 0.3, random_state = 1234, stratify=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7710965133906014\n",
      "[[3814  559]\n",
      " [ 800  764]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Import and train classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier(random_state=1234)\n",
    "dtc.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "# Test the model\n",
    "Y_predict = dtc.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Y_test, Y_predict)\n",
    "score = dtc.score(X_test, Y_test)\n",
    "\n",
    "print(score)\n",
    "print(cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve Iris Dataset problem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and load the Iris Dataset\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "\n",
    "\n",
    "# split, train test....\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = \\\n",
    "train_test_split(X, Y, test_size = 0.3, random_state = 1234, stratify=Y)\n",
    "\n",
    "# Train the SVC \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n",
      "[[15  0  0]\n",
      " [ 0 13  2]\n",
      " [ 0  1 14]]\n"
     ]
    }
   ],
   "source": [
    "# Import and train classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier(random_state=1234)\n",
    "dtc.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "# Test the model\n",
    "Y_predict = dtc.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm_iris = confusion_matrix(Y_test, Y_predict)\n",
    "score_iris = dtc.score(X_test, Y_test)\n",
    "\n",
    "print(score_iris)\n",
    "print(cm_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning and Bagging,Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div  style=\"color:blue;font-family:Candara,arial,helvetica;line-height:20px\"><strong>\n",
    "\n",
    "\n",
    "## Ensemble learning is the process by which multiple models, such as classifiers or experts, are strategically generated and combined to solve a particular computational intelligence problem. Ensemble learning is primarily used to improve the (classification, prediction, function approximation, etc.) performance of a model, or reduce the likelihood of an unfortunate selection of a poor one. \n",
    "\n",
    "## Bagging is a way to decrease the variance in the prediction by generating additional data for training from dataset using combinations with repetitions to produce multi-sets of the original data. Boosting is an iterative technique which adjusts the weight of an observation based on the last classification.  \n",
    "    \n",
    "    \n",
    "<img src=\"https://miro.medium.com/max/1169/1*_pfQ7Xf-BAwfQXtaBbNTEg.png\" alt=\"drawing\" width=\"600\" height=\"300\"/>     \n",
    "    \n",
    "<img src=\"https://miro.medium.com/max/850/1*DwvwMlOcT1T9hZwIJvMfng.png\" alt=\"drawing\" width=\"600\" height=\"300\"/>     \n",
    "   \n",
    "\n",
    "</strong></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Adult Income Dataset using Random forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library and Split into Test/Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Read dataset\n",
    "data = pd.read_csv('04 - decisiontreeAdultIncome.csv')\n",
    "\n",
    "# Check for Null values\n",
    "data.isnull().sum(axis=0)\n",
    "\n",
    "# Create Dummy variables\n",
    "data.dtypes\n",
    "data_prep = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "\n",
    "# Create X and Y Variables\n",
    "X = data_prep.iloc[:, :-1]\n",
    "Y = data_prep.iloc[:, -1]\n",
    "\n",
    "\n",
    "# Split the X and Y dataset into training and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = \\\n",
    "train_test_split(X, Y, test_size = 0.3, random_state = 1234, stratify=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3882  491]\n",
      " [ 712  852]]\n",
      "0.7973724103082365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import and train Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(random_state=1234)\n",
    "rfc.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "# Test the RFC model\n",
    "Y_predict = rfc.predict(X_test)\n",
    "\n",
    "# Evaluate the RFC model\n",
    "cm2 = confusion_matrix(Y_test, Y_predict)\n",
    "score2 = rfc.score(X_test, Y_test)\n",
    "\n",
    "print(cm2)\n",
    "print(score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving Iris problem using Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and load the Iris Dataset\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "\n",
    "\n",
    "# split, train test....\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = \\\n",
    "train_test_split(X, Y, test_size = 0.3, random_state = 1234, stratify=Y)\n",
    "\n",
    "# Train the SVC \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n",
      "[[15  0  0]\n",
      " [ 0 13  2]\n",
      " [ 0  1 14]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import and train Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(random_state=1234)\n",
    "rfc.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "# Test the model\n",
    "Y_predict = dtc.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm_iris = confusion_matrix(Y_test, Y_predict)\n",
    "score_iris = dtc.score(X_test, Y_test)\n",
    "\n",
    "print(score_iris)\n",
    "print(cm_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
